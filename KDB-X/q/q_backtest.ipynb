{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "intro-cell",
      "metadata": {
        "id": "intro-cell"
      },
      "source": [
        "# Real Market Data Backtesting with q/KDB-X\n",
        "\n",
        "This notebook demonstrates how to build a **financial backtesting system** using KDB-X/q. We'll simulate a simple trading strategy and calculate how much profit or loss it would have generated.\n",
        "\n",
        "## What we explore in this Notebook?\n",
        "\n",
        "\n",
        "- **Real market data** from Yahoo Finance (last 8 days, minute-level)\n",
        "- **Moving average crossover strategy** - a classic momentum approach\n",
        "- **15-minute bars** - aggregated from minute data for cleaner signals\n",
        "- **Complete trade analysis** - PnL, win rate, drawdowns, and more\n",
        "\n",
        "## The Strategy: Moving Average Crossover\n",
        "\n",
        "We'll implement a **dual moving average crossover**:\n",
        "- **Fast MA**: 10-period moving average (responsive to recent price action)\n",
        "- **Slow MA**: 30-period moving average (tracks longer-term trend)\n",
        "- **Buy signal**: When fast MA crosses *above* slow MA â†’ bullish momentum\n",
        "- **Sell signal**: When fast MA crosses *below* slow MA â†’ bearish momentum\n",
        "\n",
        "This is a trend-following strategy used by traders to ride momentum waves.\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "- Requires KDB-X to be installed, you can sign up and download on [Developer Center](https://developer.kx.com/products/kdb-x/install). For full install instructions see: [KDB-X Install](https://code.kx.com/kdb-x/).\n",
        "\n",
        "- To Install [KDB-X Python](https://code.kx.com/pykx/4.0/examples/jupyter-integration.html): `pip install --upgrade --pre pykx` (This is required to run q in a Python notebook, but you can run the q directly from a q session if you prefer.)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "6SAVk5CG4N_H",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SAVk5CG4N_H",
        "outputId": "b2d96a42-7054-433b-abdc-624b64ba6cc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qq --upgrade --pre pykx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "setup-cell",
      "metadata": {
        "id": "setup-cell"
      },
      "outputs": [],
      "source": [
        "import pykx as kx\n",
        "import yfinance as yf\n",
        "from datetime import datetime, timedelta"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fetch-data-md",
      "metadata": {
        "id": "fetch-data-md"
      },
      "source": [
        "## Step 1: Fetch Real Market Data\n",
        "\n",
        "We'll download the last 8 days of minute-level data for **AAPL** and **MSFT**. Yahoo Finance provides free intraday data, though it's limited to the most recent period.\n",
        "\n",
        "### Why minute data?\n",
        "Minute bars give us fine-grained price action, allowing us to:\n",
        "- Aggregate into any timeframe we want (5min, 15min, 1hr)\n",
        "- Simulate realistic entry/exit timing\n",
        "- See intraday volatility patterns\n",
        "\n",
        "We'll use Python/yfinance to fetch the data, then convert it to a q table for all subsequent analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "fetch-data-cell",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fetch-data-cell",
        "outputId": "7a1ff71c-87a1-428c-bfa7-24bed08e8382"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fetching data from 2026-01-20 to 2026-01-28...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  2 of 2 completed"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ Loaded 4,664 minute bars\n",
            "âœ“ Tickers: aapl, msft\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "/tmp/ipython-input-3175797431.py:17: FutureWarning: The previous implementation of stack is deprecated and will be removed in a future version of pandas. See the What's New notes for pandas 2.1.0 for details. Specify future_stack=True to adopt the new implementation and silence this warning.\n",
            "  data_long = data.stack(level=1).reset_index()\n"
          ]
        }
      ],
      "source": [
        "# Calculate dynamic date range (last 8 days)\n",
        "end_date = datetime.now()\n",
        "start_date = end_date - timedelta(days=8)\n",
        "\n",
        "print(f\"Fetching data from {start_date.date()} to {end_date.date()}...\")\n",
        "\n",
        "# Download minute-level data\n",
        "data = yf.download(\n",
        "    tickers=[\"AAPL\", \"MSFT\"],\n",
        "    start=start_date.strftime(\"%Y-%m-%d\"),\n",
        "    end=end_date.strftime(\"%Y-%m-%d\"),\n",
        "    interval=\"1m\",\n",
        "    auto_adjust=True\n",
        ")\n",
        "\n",
        "# Reshape from wide (columns per ticker) to long format (rows per ticker)\n",
        "data_long = data.stack(level=1).reset_index()\n",
        "\n",
        "# Rename columns to match q conventions\n",
        "data_long = data_long.rename(columns={\n",
        "    'Datetime': 'dt',\n",
        "    'Ticker': 'sym'\n",
        "})\n",
        "\n",
        "# Convert ticker symbols to lowercase (q convention)\n",
        "data_long['sym'] = data_long['sym'].str.lower()\n",
        "\n",
        "# Convert to q table - this is our bridge from Python to q\n",
        "quotes = kx.toq(data_long)\n",
        "kx.q['quotes'] = quotes\n",
        "\n",
        "print(f\"âœ“ Loaded {len(data_long):,} minute bars\")\n",
        "print(f\"âœ“ Tickers: {', '.join(data_long['sym'].unique())}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "inspect-data-md",
      "metadata": {
        "id": "inspect-data-md"
      },
      "source": [
        "## Step 2: Inspect the Data Structure\n",
        "\n",
        "Let's examine what we're working with. From here on, we use **pure q code** - no more Python!\n",
        "\n",
        "The data should have columns: `dt` (datetime), `sym` (symbol), `Open`, `High`, `Low`, `Close`, `Volume`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "zPBmJqs0IABy",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPBmJqs0IABy",
        "outputId": "b055e9bb-1c03-4832-b909-7f4cd285d498"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "KDB-X Python now running in 'jupyter_qfirst' mode. All cells by default will be run as q code.\n",
            "Include '%%py' at the beginning of each cell to run as python code. \n"
          ]
        }
      ],
      "source": [
        "# Enable q-first mode - write pure q code in subsequent cells\n",
        "kx.util.jupyter_qfirst_enable()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "RrDP5MFy8AjQ",
      "metadata": {
        "id": "RrDP5MFy8AjQ"
      },
      "outputs": [],
      "source": [
        "/ Adjust console width for visibility\n",
        "\\c 20 200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "inspect-data-cell",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inspect-data-cell",
        "outputId": "81f304aa-3fe7-4709-fe11-e1ce1616fb19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dt                            sym  Close   High    Low     Open   Volume \n",
            "-------------------------------------------------------------------------\n",
            "2026.01.20D14:30:00.000000000 aapl 254.48  254.79  252.36  252.51 2600373\n",
            "2026.01.20D14:30:00.000000000 msft 450.45  452.13  450.1   451.43 1289307\n",
            "2026.01.20D14:31:00.000000000 aapl 253.9   254.64  253.809 254.39 250428 \n",
            "2026.01.20D14:31:00.000000000 msft 450.12  450.86  449.33  450.51 253023 \n",
            "2026.01.20D14:32:00.000000000 aapl 254.3   254.57  253.83  253.91 232262 \n",
            "2026.01.20D14:32:00.000000000 msft 449.74  450.175 449.3   450.06 99677  \n",
            "2026.01.20D14:33:00.000000000 aapl 254.38  254.79  254.19  254.27 192391 \n",
            "2026.01.20D14:33:00.000000000 msft 450.32  450.5   449.28  449.69 89392  \n",
            "2026.01.20D14:34:00.000000000 aapl 254.07  254.39  253.85  254.37 181225 \n",
            "2026.01.20D14:34:00.000000000 msft 451.395 451.5   450.03  450.5  81703  \n"
          ]
        }
      ],
      "source": [
        "/ Show first 10 rows\n",
        "10 sublist quotes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "data-summary-cell",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "data-summary-cell",
        "outputId": "433a0a1d-497d-43d2-d295-a351e66cbe1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sym | bars start                         end                           low_price high_price\n",
            "----| -------------------------------------------------------------------------------------\n",
            "aapl| 2339 2026.01.20D14:30:00.000000000 2026.01.27D20:59:00.000000000 243.44    261.88    \n",
            "msft| 2325 2026.01.20D14:30:00.000000000 2026.01.27D20:59:00.000000000 438.8001  482.71    \n"
          ]
        }
      ],
      "source": [
        "/ Get data summary by symbol\n",
        "select\n",
        "  bars:count i,\n",
        "  start:min dt,\n",
        "  end:max dt,\n",
        "  low_price:min Close,\n",
        "  high_price:max Close\n",
        "  by sym from quotes\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "create-bars-md",
      "metadata": {
        "id": "create-bars-md"
      },
      "source": [
        "## Step 3: Aggregate to 15-Minute Bars\n",
        "\n",
        "Minute data can be noisy. We'll aggregate it into **15-minute OHLCV bars** for cleaner signals.\n",
        "\n",
        "### The Process:\n",
        "1. Extract the time component from each datetime\n",
        "2. Use [`xbar`](https://code.kx.com/q/ref/xbar/) to bucket times into 15-minute intervals\n",
        "3. Aggregate: first Open, max High, min Low, last Close, sum Volume\n",
        "4. Group by symbol and time bucket\n",
        "\n",
        "This is standard OHLC bar construction used throughout finance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "create-bars-cell",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "create-bars-cell",
        "outputId": "4a6ecfe1-b4ca-41b5-d15c-0d678de32670"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15-minute bars created:\n",
            "sym  open   high   low     close   volume  dt                           \n",
            "------------------------------------------------------------------------\n",
            "aapl 252.51 254.79 252.36  254.48  2600373 2026.01.20D14:30:00.000000000\n",
            "aapl 254.39 254.64 253.809 253.9   250428  2026.01.20D14:31:00.000000000\n",
            "aapl 253.91 254.57 253.83  254.3   232262  2026.01.20D14:32:00.000000000\n",
            "aapl 254.27 254.79 254.19  254.38  192391  2026.01.20D14:33:00.000000000\n",
            "aapl 254.37 254.39 253.85  254.07  181225  2026.01.20D14:34:00.000000000\n",
            "aapl 254.02 254.16 253.3   253.57  186460  2026.01.20D14:35:00.000000000\n",
            "aapl 253.55 253.58 252.5   252.76  152844  2026.01.20D14:36:00.000000000\n",
            "aapl 252.76 252.99 252.57  252.67  121456  2026.01.20D14:37:00.000000000\n",
            "aapl 252.64 253.66 252.47  253.465 142247  2026.01.20D14:38:00.000000000\n",
            "aapl 253.43 253.44 253.03  253.08  124974  2026.01.20D14:39:00.000000000\n"
          ]
        }
      ],
      "source": [
        "/ Extract date and time components\n",
        "quotes:update date:`date$dt, time:`time$dt from quotes;\n",
        "\n",
        "/ Create 15-minute time buckets using xbar\n",
        "/ xbar rounds down to nearest interval (e.g., 14:37 -> 14:30)\n",
        "quotes:update bucket:15 xbar time from quotes;\n",
        "\n",
        "/ Aggregate to 15-minute bars\n",
        "bars:select\n",
        "  open:first Open,\n",
        "  high:max High,\n",
        "  low:min Low,\n",
        "  close:last Close,\n",
        "  volume:sum Volume\n",
        "  by sym, date, bucket from quotes;\n",
        "\n",
        "/ Recreate datetime column and clean up\n",
        "bars:update dt:date+bucket from bars;\n",
        "bars:delete date,bucket from bars;\n",
        "\n",
        "/ Sort by symbol and datetime for efficiency\n",
        "bars:`sym`dt xasc bars;\n",
        "\n",
        "\"15-minute bars created:\"\n",
        "10 sublist bars"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "calc-ma-md",
      "metadata": {
        "id": "calc-ma-md"
      },
      "source": [
        "## Step 4: Calculate Moving Averages\n",
        "\n",
        "Now we calculate our strategy indicators:\n",
        "- **Fast MA**: 10-period moving average using [`mavg`](https://code.kx.com/q/ref/avg/#mavg)\n",
        "- **Slow MA**: 30-period moving average\n",
        "\n",
        "The `by sym` clause ensures we calculate MAs separately for each ticker - no data leakage between symbols!\n",
        "\n",
        "A 10-period moving average is the average closing price of the last 10 fifteen-minute bars (fast-moving, reacts quickly to recent price changes), while a 30-period moving average is the average closing price of the last 30 fifteen-minute bars (slow-moving, smooths out short-term fluctuations to show the longer-term trend).\n",
        "\n",
        "### Identifying Crossovers\n",
        "A crossover occurs when:\n",
        "- **Bullish**: Fast MA was â‰¤ Slow MA, now Fast MA > Slow MA\n",
        "- **Bearish**: Fast MA was â‰¥ Slow MA, now Fast MA < Slow MA\n",
        "\n",
        "We use [`prev`](https://code.kx.com/q/ref/next/) to access the previous row's values for comparison."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "calc-ma-cell",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "calc-ma-cell",
        "outputId": "d8e53712-4243-4ee2-e0c7-1771b18e784f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trading signals generated:\n",
            "sym  open     high   low      close    volume  dt                            ma_fast  ma_slow  prev_fast prev_slow signal\n",
            "-------------------------------------------------------------------------------------------------------------------------\n",
            "aapl 253.09   253.14 252.6    252.74   123556  2026.01.20D14:40:00.000000000 253.4935 253.5832 253.6675  253.6675  -1    \n",
            "aapl 251.4701 251.74 251.445  251.6157 99923   2026.01.20D15:29:00.000000000 251.5011 251.4717 251.4335  251.5038  1     \n",
            "aapl 251.29   251.33 251.19   251.215  54891   2026.01.20D15:39:00.000000000 251.3346 251.3358 251.3747  251.3416  -1    \n",
            "aapl 251.78   252.06 251.76   252.06   79390   2026.01.20D16:01:00.000000000 251.338  251.3233 251.244   251.3     1     \n",
            "aapl 251.45   251.55 251.36   251.36   42067   2026.01.20D16:21:00.000000000 251.545  251.5538 251.592   251.5458  -1    \n",
            "aapl 251.5084 251.55 251.43   251.445  48272   2026.01.20D16:40:00.000000000 251.3716 251.3599 251.3331  251.3725  1     \n",
            "aapl 250.87   250.87 250.82   250.8503 43375   2026.01.20D16:44:00.000000000 251.2422 251.2451 251.2892  251.2728  -1    \n",
            "aapl 251.24   251.28 251.14   251.15   41432   2026.01.20D17:03:00.000000000 251.0464 251.0329 250.9764  251.0376  1     \n",
            "aapl 250.73   250.77 250.66   250.76   42190   2026.01.20D17:14:00.000000000 250.912  250.9138 250.941   250.9168  -1    \n",
            "aapl 247.82   247.82 247.6701 247.703  50282   2026.01.20D19:44:00.000000000 247.7573 247.7123 247.717   247.7266  1     \n",
            "aapl 247.35   247.35 247.01   247.105  94658   2026.01.20D19:51:00.000000000 247.5258 247.5842 247.6253  247.6087  -1    \n",
            "aapl 246.13   246.93 245.82   246.69   2043971 2026.01.20D20:59:00.000000000 245.1287 244.9296 244.8717  244.8886  1     \n",
            "aapl 247.05   247.05 246.39   246.4138 66083   2026.01.21D15:07:00.000000000 246.9384 246.9436 247.017   246.9691  -1    \n",
            "aapl 247.11   247.28 247.1    247.165  38574   2026.01.21D15:20:00.000000000 246.9945 246.9597 246.9105  246.9609  1     \n",
            "aapl 248.205  248.22 247.91   247.92   54717   2026.01.21D16:02:00.000000000 248.2108 248.2295 248.2518  248.2271  -1    \n",
            "..\n"
          ]
        }
      ],
      "source": [
        "/ Calculate moving averages per symbol\n",
        "bars:update\n",
        "  ma_fast:mavg[10;close],\n",
        "  ma_slow:mavg[30;close]\n",
        "  by sym from bars;\n",
        "\n",
        "/ Get previous values for crossover detection\n",
        "bars:update\n",
        "  prev_fast:prev ma_fast,\n",
        "  prev_slow:prev ma_slow\n",
        "  by sym from bars;\n",
        "\n",
        "/ Identify crossover signals\n",
        "/ signal = 1: bullish cross (BUY)\n",
        "/ signal = -1: bearish cross (SELL)\n",
        "/ signal = 0: no signal\n",
        "bars:update signal:0 from bars;\n",
        "bars:update signal:1 from bars where (ma_fast>ma_slow) and prev_fast<=prev_slow;\n",
        "bars:update signal:-1 from bars where (ma_fast<ma_slow) and prev_fast>=prev_slow;\n",
        "\n",
        "\"Trading signals generated:\"\n",
        "select from bars where signal<>0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "generate-trades-md",
      "metadata": {
        "id": "generate-trades-md"
      },
      "source": [
        "## Step 5: Generate Trade Pairs\n",
        "\n",
        "We have signals, now we need to pair them up into actual trades:\n",
        "- Each **BUY signal** (signal=1) is an entry\n",
        "- Each **SELL signal** (signal=-1) is an exit\n",
        "- We match each entry with the next exit using an asof join\n",
        "\n",
        "### Why Asof Join?\n",
        "The [`aj`](https://code.kx.com/q/ref/aj/) function finds the \"most recent match as of a time\" - perfect for matching \"next exit after this entry\".\n",
        "\n",
        "We'll trade 100 shares per position for simplicity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "generate-trades-cell",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "generate-trades-cell",
        "outputId": "5882f7e8-07fc-4d53-e728-253926f853ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated positions:\n",
            "sym  entry_dt                      entry_price exit_dt                       exit_price size\n",
            "--------------------------------------------------------------------------------------------\n",
            "aapl 2026.01.20D15:29:00.000000000 251.6157    2026.01.20D15:39:00.000000000 251.215    100 \n",
            "aapl 2026.01.20D16:01:00.000000000 252.06      2026.01.20D16:21:00.000000000 251.36     100 \n",
            "aapl 2026.01.20D16:40:00.000000000 251.445     2026.01.20D16:44:00.000000000 250.8503   100 \n",
            "aapl 2026.01.20D17:03:00.000000000 251.15      2026.01.20D17:14:00.000000000 250.76     100 \n",
            "aapl 2026.01.20D19:44:00.000000000 247.703     2026.01.20D19:51:00.000000000 247.105    100 \n",
            "aapl 2026.01.20D20:59:00.000000000 246.69      2026.01.21D15:07:00.000000000 246.4138   100 \n",
            "aapl 2026.01.21D15:20:00.000000000 247.165     2026.01.21D16:02:00.000000000 247.92     100 \n",
            "aapl 2026.01.21D17:25:00.000000000 246.0199    2026.01.21D18:05:00.000000000 245.83     100 \n",
            "aapl 2026.01.21D18:14:00.000000000 246.2       2026.01.21D18:26:00.000000000 245.89     100 \n",
            "aapl 2026.01.21D18:50:00.000000000 246.16      2026.01.21D19:08:00.000000000 245.97     100 \n",
            "aapl 2026.01.21D19:28:00.000000000 246.91      2026.01.21D20:18:00.000000000 249.35     100 \n",
            "aapl 2026.01.22D14:33:00.000000000 249.35      2026.01.22D14:53:00.000000000 249.16     100 \n",
            "aapl 2026.01.22D15:04:00.000000000 250.025     2026.01.22D15:26:00.000000000 249.8      100 \n",
            "aapl 2026.01.22D15:34:00.000000000 249.94      2026.01.22D15:40:00.000000000 249.76     100 \n",
            "aapl 2026.01.22D16:11:00.000000000 249.75      2026.01.22D16:35:00.000000000 249.4198   100 \n",
            "..\n"
          ]
        }
      ],
      "source": [
        "/ Extract buy and sell signals\n",
        "trades:select sym, dt, signal, close from bars where signal<>0;\n",
        "trades:update tradetype:`buy from trades where signal=1;\n",
        "trades:update tradetype:`sell from trades where signal=-1;\n",
        "\n",
        "/ Separate buys and sells\n",
        "buys:select sym, entry_dt:dt, entry_price:close from trades where tradetype=`buy;\n",
        "sells:select sym, exit_dt:dt, exit_price:close from trades where tradetype=`sell;\n",
        "\n",
        "/ Apply sorted attribute for efficient joining\n",
        "buys:update `s#sym from `sym xasc buys;\n",
        "sells:update `s#sym from `sym xasc sells;\n",
        "\n",
        "/ Match each SELL with its most recent preceding BUY using asof join (backward-looking)\n",
        "/ Rename entry_dtâ†’exit_dt temporarily so aj finds the buy that occurred at or before each sell\n",
        "positions:aj[`sym`exit_dt;sells;update exit_dt:entry_dt from buys];\n",
        "positions:select sym, entry_dt, entry_price, exit_dt, exit_price from positions;\n",
        "\n",
        "/ Remove incomplete trades where no matching buy was found (null entry_price)\n",
        "positions:delete from positions where null entry_price;\n",
        "\n",
        "/ Set position size\n",
        "positions:update size:100 from positions;\n",
        "\n",
        "\"Generated positions:\"\n",
        "positions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "calc-pnl-md",
      "metadata": {
        "id": "calc-pnl-md"
      },
      "source": [
        "## Step 6: Calculate PnL\n",
        "\n",
        "For each position, we calculate:\n",
        "- **PnL in dollars**: `size Ã— (exit_price - entry_price)`\n",
        "- **PnL percentage**: `100 Ã— (exit_price - entry_price) / entry_price`\n",
        "- **Holding period**: How long we held the position\n",
        "\n",
        "This tells us which trades were winners and losers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "calc-pnl-cell",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "calc-pnl-cell",
        "outputId": "46257445-9b97-47ed-993c-6f2d11440a46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Position PnL: \n",
            "sym  entry_dt                      entry_price exit_dt                       exit_price size pnl       pnl_pct     holding_period      \n",
            "---------------------------------------------------------------------------------------------------------------------------------------\n",
            "aapl 2026.01.20D15:29:00.000000000 251.6157    2026.01.20D15:39:00.000000000 251.215    100  -40.07111 -0.1592552  0D00:10:00.000000000\n",
            "aapl 2026.01.20D16:01:00.000000000 252.06      2026.01.20D16:21:00.000000000 251.36     100  -69.99969 -0.2777104  0D00:20:00.000000000\n",
            "aapl 2026.01.20D16:40:00.000000000 251.445     2026.01.20D16:44:00.000000000 250.8503   100  -59.47113 -0.2365174  0D00:04:00.000000000\n",
            "aapl 2026.01.20D17:03:00.000000000 251.15      2026.01.20D17:14:00.000000000 250.76     100  -38.99994 -0.1552854  0D00:11:00.000000000\n",
            "aapl 2026.01.20D19:44:00.000000000 247.703     2026.01.20D19:51:00.000000000 247.105    100  -59.80072 -0.2414211  0D00:07:00.000000000\n",
            "aapl 2026.01.20D20:59:00.000000000 246.69      2026.01.21D15:07:00.000000000 246.4138   100  -27.61993 -0.1119621  0D18:08:00.000000000\n",
            "aapl 2026.01.21D15:20:00.000000000 247.165     2026.01.21D16:02:00.000000000 247.92     100  75.50049  0.3054659   0D00:42:00.000000000\n",
            "aapl 2026.01.21D17:25:00.000000000 246.0199    2026.01.21D18:05:00.000000000 245.83     100  -18.98956 -0.0771871  0D00:40:00.000000000\n",
            "aapl 2026.01.21D18:14:00.000000000 246.2       2026.01.21D18:26:00.000000000 245.89     100  -30.99976 -0.1259129  0D00:12:00.000000000\n",
            "aapl 2026.01.21D18:50:00.000000000 246.16      2026.01.21D19:08:00.000000000 245.97     100  -19.00024 -0.07718656 0D00:18:00.000000000\n",
            "aapl 2026.01.21D19:28:00.000000000 246.91      2026.01.21D20:18:00.000000000 249.35     100  244.0002  0.9882153   0D00:50:00.000000000\n",
            "aapl 2026.01.22D14:33:00.000000000 249.35      2026.01.22D14:53:00.000000000 249.16     100  -19.00024 -0.07619909 0D00:20:00.000000000\n",
            "aapl 2026.01.22D15:04:00.000000000 250.025     2026.01.22D15:26:00.000000000 249.8      100  -22.49908 -0.08998734 0D00:22:00.000000000\n",
            "aapl 2026.01.22D15:34:00.000000000 249.94      2026.01.22D15:40:00.000000000 249.76     100  -18.00079 -0.07202046 0D00:06:00.000000000\n",
            "aapl 2026.01.22D16:11:00.000000000 249.75      2026.01.22D16:35:00.000000000 249.4198   100  -33.02002 -0.1322123  0D00:24:00.000000000\n",
            "..\n"
          ]
        }
      ],
      "source": [
        "/ Calculate PnL metrics for each trade\n",
        "positions:update\n",
        "  pnl:size * exit_price - entry_price,\n",
        "  pnl_pct:100 * (exit_price - entry_price) % entry_price,\n",
        "  holding_period:exit_dt - entry_dt\n",
        "  from positions;\n",
        "\n",
        "\"Position PnL: \"\n",
        "positions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "SwYSSOnC0b42",
      "metadata": {
        "id": "SwYSSOnC0b42"
      },
      "outputs": [],
      "source": [
        "/ Extract the pnl values\n",
        "pnl:positions`pnl;"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "symbol-analysis-md",
      "metadata": {
        "id": "symbol-analysis-md"
      },
      "source": [
        "## Step 7: Performance by Symbol\n",
        "\n",
        "Different stocks behave differently. Let's break down performance by ticker to see which one the strategy works better on.\n",
        "\n",
        "We might find:\n",
        "- One stock trends more consistently (better for MA crossover)\n",
        "- One stock is choppier (more whipsaws, lower win rate)\n",
        "- Differences in volatility and trade frequency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "symbol-analysis-cell",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "symbol-analysis-cell",
        "outputId": "43b49bec-f0a5-415b-a0cd-73e36f062008"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sym | trades winners total_pnl avg_pnl  win_rate best_trade worst_trade\n",
            "----| -----------------------------------------------------------------\n",
            "aapl| 48     14      251.4755  5.239073 29.16667 405.0003   -94.00024  \n",
            "msft| 45     15      2006.519  44.5893  33.33333 1609       -162.9974  \n"
          ]
        }
      ],
      "source": [
        "/ Aggregate statistics by symbol\n",
        "symbol_stats:select\n",
        "  trades:count i,\n",
        "  winners:sum pnl>0,\n",
        "  total_pnl:sum pnl,\n",
        "  avg_pnl:avg pnl,\n",
        "  win_rate:100 * (sum pnl>0) % count i,\n",
        "  best_trade:max pnl,\n",
        "  worst_trade:min pnl\n",
        "  by sym from positions;\n",
        "\n",
        "-1 \"\\n=== PERFORMANCE BY SYMBOL ===\";\n",
        "symbol_stats"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cumulative-pnl-md",
      "metadata": {
        "id": "cumulative-pnl-md"
      },
      "source": [
        "## Step 8: Cumulative PnL Over Time\n",
        "\n",
        "To understand the strategy's progression, we calculate cumulative PnL - how our account balance would have grown (or shrunk) over the backtest period.\n",
        "\n",
        "The [`sums`](https://code.kx.com/q/ref/sum/#sums) function creates a running total, perfect for equity curves."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "cumulative-pnl-cell",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cumulative-pnl-cell",
        "outputId": "e4706472-13b3-4085-c9ef-011a1cc29751"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUMULATIVE PnL OVER TIME: \n",
            "entry_dt                      sym  pnl       cumulative_pnl\n",
            "-----------------------------------------------------------\n",
            "2026.01.27D17:13:00.000000000 aapl -19.00024 2538.133      \n",
            "2026.01.27D17:15:00.000000000 aapl -9.960938 2528.172      \n",
            "2026.01.27D17:30:00.000000000 msft 39.4989   2567.671      \n",
            "2026.01.27D18:13:00.000000000 aapl -27.00195 2540.669      \n",
            "2026.01.27D18:14:00.000000000 msft -16.99829 2523.671      \n",
            "2026.01.27D18:47:00.000000000 msft 26.32141  2549.992      \n",
            "2026.01.27D19:05:00.000000000 aapl -13.50098 2536.491      \n",
            "2026.01.27D19:21:00.000000000 aapl -22.50061 2513.991      \n",
            "2026.01.27D19:29:00.000000000 msft -42.99927 2470.992      \n",
            "2026.01.27D19:33:00.000000000 msft -6.500244 2464.491      \n",
            "2026.01.27D19:56:00.000000000 msft -46.49963 2417.992      \n",
            "2026.01.27D19:59:00.000000000 aapl -20.49866 2397.493      \n",
            "2026.01.27D20:42:00.000000000 msft -29.49829 2367.995      \n",
            "2026.01.27D20:47:00.000000000 aapl -55.00183 2312.993      \n",
            "2026.01.27D20:49:00.000000000 msft -54.99878 2257.994      \n"
          ]
        }
      ],
      "source": [
        "/ Sort trades chronologically and calculate running PnL\n",
        "pnl_timeline:`entry_dt xasc select entry_dt, sym, pnl from positions;\n",
        "pnl_timeline:update cumulative_pnl:sums pnl from pnl_timeline;\n",
        "\n",
        "\"CUMULATIVE PnL OVER TIME: \"\n",
        "-15 sublist pnl_timeline"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "drawdown-md",
      "metadata": {
        "id": "drawdown-md"
      },
      "source": [
        "## Step 9: Maximum Drawdown Analysis\n",
        "\n",
        "**Maximum drawdown** is the largest peak-to-trough decline in cumulative PnL. It measures the strategy's worst-case risk.\n",
        "\n",
        "### Why it matters:\n",
        "- Shows how much capital you could have lost at the worst point\n",
        "- Helps determine position sizing and risk tolerance\n",
        "- More realistic than just looking at final PnL\n",
        "\n",
        "We calculate:\n",
        "1. Running maximum PnL at each point (the peak)\n",
        "2. Current drawdown = Current PnL - Running maximum\n",
        "3. Maximum drawdown = Largest negative value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "drawdown-cell",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drawdown-cell",
        "outputId": "098d6364-df26-48d3-e07b-7ab8d039972d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Maximum Drawdown: $-747.67\n",
            "Worst drawdown period:\n",
            "entry_dt                      sym  pnl       cumulative_pnl running_max drawdown\n",
            "--------------------------------------------------------------------------------\n",
            "2026.01.21D18:55:00.000000000 msft -150.5005 -478.4195      269.2505    -747.67 \n"
          ]
        }
      ],
      "source": [
        "/ Calculate running maximum (the peak)\n",
        "pnl_timeline:update running_max:maxs cumulative_pnl from pnl_timeline\n",
        "\n",
        "/ Calculate drawdown from peak\n",
        "pnl_timeline:update drawdown:cumulative_pnl - running_max from pnl_timeline\n",
        "\n",
        "/ Find maximum drawdown\n",
        "max_dd:min pnl_timeline[`drawdown]\n",
        "\"Maximum Drawdown: $\", string max_dd\n",
        "\n",
        "/ Show when it occurred\n",
        "\"Worst drawdown period:\"\n",
        "select from pnl_timeline where drawdown = min drawdown"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "parameter-test-md",
      "metadata": {
        "id": "parameter-test-md"
      },
      "source": [
        "## Step 10: Testing Different Parameters\n",
        "\n",
        "What if we used **different MA periods**? Let's try a faster 5/20 combination and compare signal frequency.\n",
        "\n",
        "### Trade-offs:\n",
        "- **Shorter MAs** (5/20): More signals, more responsive, but more whipsaws\n",
        "- **Longer MAs** (10/30): Fewer signals, smoother, but slower to react\n",
        "\n",
        "This is called **parameter sensitivity analysis** - testing how results change with different settings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "parameter-test-cell",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "parameter-test-cell",
        "outputId": "c4270340-ff81-45b2-93c8-22cd61bd6224"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SIGNAL FREQUENCY COMPARISON: \n",
            "strategy signals\n",
            "----------------\n",
            "MA_10_30 187    \n",
            "MA_5_20  285    \n"
          ]
        }
      ],
      "source": [
        "/ Calculate alternative moving averages (5/20)\n",
        "bars2:update\n",
        "  ma_fast5:mavg[5;close],\n",
        "  ma_slow20:mavg[20;close]\n",
        "  by sym from bars;\n",
        "\n",
        "/ Detect crossovers with new parameters\n",
        "/ To detect a \"crossover,\" we need to know the values from the PREVIOUS row.\n",
        "/ 'prev' shifts the data down by one, allowing us to compare 'now' vs 'then'.\n",
        "bars2:update\n",
        "  prev_fast5:prev ma_fast5,\n",
        "  prev_slow20:prev ma_slow20\n",
        "  by sym from bars2;\n",
        "\n",
        "/ Initialize all signals to 0 (No Trade/Hold)\n",
        "bars2:update signal2:0 from bars2;\n",
        "\n",
        "/ BULLISH CROSSOVER:\n",
        "/ Fast MA is currently ABOVE slow MA, but was BELOW or EQUAL in the previous bar.\n",
        "bars2:update signal2:1 from bars2 where (ma_fast5>ma_slow20) and prev_fast5<=prev_slow20;\n",
        "\n",
        "/ BEARISH CROSSOVER:\n",
        "/ Fast MA is currently BELOW slow MA, but was ABOVE or EQUAL in the previous bar\n",
        "bars2:update signal2:-1 from bars2 where (ma_fast5<ma_slow20) and prev_fast5>=prev_slow20;\n",
        "\n",
        "/ Compare signal counts\n",
        "signal_count:([]\n",
        "  strategy:`$(\"MA_10_30\";\"MA_5_20\");\n",
        "  signals:(sum abs bars[`signal]; sum abs bars2[`signal2])\n",
        "  );\n",
        "\n",
        "\"SIGNAL FREQUENCY COMPARISON: \"\n",
        "signal_count"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oQHh77bw3jj6",
      "metadata": {
        "id": "oQHh77bw3jj6"
      },
      "source": [
        "#### Challenge: Can you find the PnL stats for this new 5/20 Moving Average strategy?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Q79GF-0x3e0o",
      "metadata": {
        "id": "Q79GF-0x3e0o"
      },
      "outputs": [],
      "source": [
        "/ Challenge Code:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "conclusion-md",
      "metadata": {
        "id": "conclusion-md"
      },
      "source": [
        "## Conclusion and Next Steps\n",
        "\n",
        "### What We Built\n",
        "\n",
        "This notebook demonstrated:\n",
        "1. **Real data integration**: Yahoo Finance â†’ q/KDB-X pipeline\n",
        "2. **Bar aggregation**: Minute data â†’ 15-minute OHLC bars\n",
        "3. **Technical indicators**: Moving averages with `mavg`\n",
        "4. **Signal generation**: Crossover detection logic\n",
        "5. **Trade matching**: Entry/exit pairing with `aj`\n",
        "6. **Performance analysis**: PnL, win rate, drawdown, cumulative returns\n",
        "7. **Parameter testing**: Comparing different MA periods\n",
        "\n",
        "### Key q/KDB-X Features Used\n",
        "\n",
        "- **`xbar`**: Time bucketing for bar aggregation\n",
        "- **`mavg`**: Efficient moving averages\n",
        "- **`by` clause**: Per-symbol calculations without loops\n",
        "- **`aj` (asof join)**: Time-series matching for trade pairing\n",
        "- **`sums` / `maxs`**: Running calculations for equity curves\n",
        "- **`prev`**: Access previous row values for crossover detection\n",
        "- **Attributes (`` `s# ``)**: Performance optimization for sorted data\n",
        "\n",
        "### Improvements for Production\n",
        "\n",
        "To make this a real trading strategy, add:\n",
        "\n",
        "1. **Transaction costs**: Commissions ($0.005/share?), slippage (1-2 bps?)\n",
        "2. **Position sizing**: Risk-based sizing, not fixed 100 shares\n",
        "3. **Risk management**: Stop losses, maximum position limits\n",
        "4. **Multiple timeframes**: Confirm signals on higher timeframes\n",
        "5. **Volume filters**: Ignore signals on low-volume bars\n",
        "6. **Market regime detection**: Different parameters for trending vs ranging markets\n",
        "7. **Walk-forward testing**: Test on rolling windows to avoid overfitting\n",
        "8. **Realistic execution**: Model market impact, time-in-force\n",
        "\n",
        "### Why q/KDB-X?\n",
        "\n",
        "This example used just 8 days of minute data. In production:\n",
        "- Backtests run on **years of tick data** (billions of records)\n",
        "- Real-time strategies process **millions of quotes per second**\n",
        "- Portfolio analytics aggregate **thousands of instruments simultaneously**\n",
        "\n",
        "q/KDB-X excels at these scales with the same clean syntax we used here. The code patterns are identical whether you're processing 10,000 rows or 10 billion.\n",
        "\n",
        "### Resources\n",
        "\n",
        "- [q Reference Card](https://code.kx.com/q/ref/)\n",
        "- [Time-series joins (aj, asof)](https://code.kx.com/q/ref/aj/)\n",
        "- [Moving averages (mavg)](https://code.kx.com/q/ref/avg/#mavg)\n",
        "- [KDB-X Python Documentation](https://code.kx.com/pykx/)\n",
        "\n",
        "Happy backtesting! ðŸš€"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ed7yef2RZ9QL",
      "metadata": {
        "id": "Ed7yef2RZ9QL"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
