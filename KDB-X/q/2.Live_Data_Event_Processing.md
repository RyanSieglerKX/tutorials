# Live Data Ingestion and Real-Time Event Processing

Welcome to this tutorial, where we'll explore how to set up a complete streaming workflow in KDB-X by ingesting live data feeds and processing real-time event streams. This tutorial will guide you through building a client-server architecture for ingesting data, appending it dynamically, and performing event-driven analytics on incoming data.

One of the key strengths of KDB-X is its ability to efficiently handle real-time data, making it an ideal choice for applications such as financial market data processing, IoT sensor monitoring, and high-speed telemetry analytics.

By the end of this tutorial, you will understand how to:

*   Establish a real-time data ingestion pipeline
*   Append incoming data dynamically to an in-memory table
*   Process real-time event streams and detect patterns
*   Implement monitoring and alerting based on data thresholds


## 1. Prerequisites

Before starting this tutorial, ensure that you have KDB-X along with KDB-X Python installed on your system. If you haven't installed these yet, you can sign up at https://developer.kx.com/products/kdb-x/install.

To run the code in this tutorial you will need to launch multiple q terminals.

## 2. Setup the Server

A server in KDB-X is simply a process that listens for incoming data from other processes. This is useful in real-world scenarios where multiple sources (e.g., market data providers, sensors, trading engines) send real-time data to a centralized system.

First, let's setup a server process that listens for incoming data and stores it in an in-memory table. Run the following command in a terminal to launch a process specifying the port 1234 with `-q`.

```
$ q -p 1234
```
By setting a port we have exposed this process so other clients can send data to it, the serve is now listening for incoming connections on port 1234.

Next, we can create an empty in-memory table named `trade`, which will store our real-time data.

```q
// Server
trade:([]time:`timestamp$();sym:`$();price:`float$();size:`long$())
```

Here's a breakdown of what's happening:

*   We define a new table with table notation `([] col1:<values>; col2:<values>: ....)` with empty values `()`:
    *   `time` :Timestamp of the trade
    *   `sym` :Symbol
    *   `price` :Trade price
    *   `size` :Trade volume

Now the server and table are ready to receive data!

## 3. Setup the Client

The client acts as a data source that continuously sends new trade events to the server. In real-world scenarios, this could be a market data feed, an IoT sensor, or a trading algorithm.

Open a second q session (client process) and establish a connection to the server using <a href="https://code.kx.com/q/ref/hopen/#hopen" target="_blank">hopen</a>:

```
$ q
```
```q
// Client
h:hopen 1234
```

In the above:

*   `hopen 1234` creates a connection handle (h) to communicate with the server.
*   If the server is not running, this would return an error.

The client is now connected to the server and ready to send data!

In KDB-X, a client can send commands to a server using IPC (`hopen`). One way to add data to a table is by upserting new records into the table stored on the server.

Let's define a function `genData` to generate trade data.

```q
// Client
genData:{[n] ([] time:n#.z.P; sym:n?`A`B`C; price:10+n?10f; size:50*1+n?20)}
```

In the above:

*   `{[]...}` is the syntax of function definition where we can pass any parameter values within `[]`, in our case this is `n` number of rows to create
*   We define a table with table notation `([] col1:<values>; col2:<values>: ....)` that matches the table schema on our server process
    *   `time` is populated with timestamps using `#` to select
    *   `sym` is populated with random symbols selected from a list using `?`
    *   `price` and trade `size` are randomnly generated

Let's test this works by passing 2 as the parameter `n` and we see that 2 rows of data are been generated.

```q
// Client 
genData 2
```
    time                          sym price    size
    -----------------------------------------------
    2025.02.05D14:58:49.969964340 C   15.1598  650 
    2025.02.05D14:58:49.969964340 B   14.06664 450 
    

Great, next the server needs a way to receive and handle this data. This is typically done by defining a function named `upd` that acts as a [callback](#https://en.wikipedia.org/wiki/Callback_(computer_programming)).

```q
// Server
upd:{[tbl; data] upsert[tbl; data]}
```

In the above:
- `upd` is a conventionally named function used in IPC-based communication. It's short for "update" and is commonly used to handle incoming data from remote processes (like clients).
- The function takes two parameters:
    - `tbl`: a symbol representing the name of the table
    - `data`: a table or list of rows to insert
- The body of the function uses upsert to insert or update data in the target table on the server.

> **Note:**  
> While `upd` is not a built-in function it’s a widely-used naming convention. The key is that both the client and server agree on this name so that the client can remotely call it over IPC. It's a standard convention, especially in real-time systems like [tick architecture](https://github.com/KxSystems/kdb-tick), where it's used to handle data updates flowing from a tickerplant to subscribers such as real-time databases (RDB) or historical databases (HDB).

Now, `upd` is defined on the receiving server process, we are ready to send data to our server process using the handle `h`.

```q
// Client 
sendData:{[n] neg[h] (`upd;`trade;genData[n])}
```

In the above:

*   <a href="https://code.kx.com/q/basics/ipc/#async-message-set" target="_blank">neg[h]</a> Sends the command to the server process, using `neg` to send asynchronously meaning we do not wait for the code to finish execution to proceed
*   `(x;y;z)` Round brackets and semicolon here allow us to send the message as a list where:
    *   `upd` Updates the table
    *   `trade` Is the table name on server process to append data to
    *   `genData[n]` Generates `n` rows of data

Let's run this for 5 rows of data and check the table on the server:

```q
// Client 
sendData 5
```
```q
// Server
select from trade
```
    time                          sym price    size
    -----------------------------------------------
    2025.02.05D15:04:05.137048916 A   12.29662 600 
    2025.02.05D15:04:05.137048916 B   16.91953 300 
    2025.02.05D15:04:05.137048916 C   14.70788 350 
    2025.02.05D15:04:05.137048916 B   16.34672 100 
    2025.02.05D15:04:05.137048916 C   19.6724  300 
    

We can see 5 rows of data have been send from the client to the server process!

## 4. Simulate a Continuous Data Feed

In real-world applications, data arrives continuously rather than in batches. Instead of manually sending data, we can automate the process using a timer that simulates an incoming data feed.

KDB-X provides a built-in timer function (`.z.ts`), which executes a given command at a set interval, we define this on the client process.

```q
// Client 
.z.ts:{sendData 5+rand 5};
\t 1000
```
In the above:

*   `.z.ts` calls `sendData`, which sends 5-9 new trades to the server
*   Using `\t` we trigger it to run every 1000 milliseconds (1 second)

We can run a `count` on the table `t` on our server process to see this in actiom , run it a few times to see the number increasing.

```q
// Server 
count trade
```
You should now see a growing table of trades appearing every second.

At this point, the server continuously receives new trade data just like a real-time market data feed!

## 5. Implementing Real-Time Alerts

Now that the server can receive streaming data from the client, let's take it a step further by introducing alerting logic.

In many real-world systems, real-time monitoring is crucial — for example:
- Triggering an alert when a stock price spikes beyond a threshold
- Flagging unusual activity in sensor data
- Notifying when trade volume exceeds a limit

We'll modify the server-side `upd` function so it not only stores data, but also checks it for conditions that trigger alerts.

### Define an alert function

First on the server, let's define a simple alert function that checks the incoming data for any price above 19 and prints an alert if true:

```q
// Server
alert:{[data] price:(max data`price);if[price > 19; show "ALERT: Price ", string[price], " exceeded 19"]}
```
Explanation:
- The function takes a batch of incoming `data`.
- It computes the max of the price column.
- If the maximum price exceeds 19, it prints a message to the console.

### Modify `upd` to include alerts

Update the server’s `upd` function to call `alert` after storing the data:

```q
// Server
upd:{[tbl; data] upsert[tbl; data]; alert[data]}
```

Now, every time the client sends new data, the server will:
- Insert the records into its table.
- Automatically evaluate them for any prices above 19.
- Print alerts to the terminal if any condition is met.


As long as the timer is still running on the client process you should start to see ALERTS being published on the server process anytime a price exceeds 19.

    "ALERT: Price 19.59409 exceeded 19"
    "ALERT: Price 19.4937 exceeded 19"
    "ALERT: Price 19.30361 exceeded 19"

This kind of logic is the foundation of real-time surveillance systems, and can be extended with more complex conditions, logging, or even triggering downstream workflows.


## 5. Logging Alerts

Let's do more step and send these alerts to a logfile instead of printing them in the process. This is more realistic to how a real life system would handle notifications.

Let's assume we want to create a new file to start writing a log to, we can create this file by opening a handle to it with `hopen`:

```q
// Server
myFileHandle: hopen `:myLog.txt
```    

Using `key` we can see this is in our current directory now as it returns the path so we know it exists.

```q
// Server
key `:myLog.txt
```
    

Next, we can adjust `alert` in our server process to write to this file instead of printing.

```q
// Server
alert:{[data] price:(max data`price);if[price > 19; neg[myFileHandle]("ALERT: Price ", string[price], " exceeded 19")]}
```
    

After defining the above you should notice alerts are no longer printing out in the process. We can use the `read0` function to check the logfile.

```q
// Server
read0 `:myLog.txt
```
    "ALERT: Price 19.72533 exceeded 19"
    "ALERT: Price 19.74431 exceeded 19"
    "ALERT: Price 19.56339 exceeded 19"
    "ALERT: Price 19.8689 exceeded 19"
    "ALERT: Price 19.58704 exceeded 19"
    "ALERT: Price 19.68696 exceeded 19"
    "ALERT: Price 19.63594 exceeded 19"
    

When we run this we can see our logfile now contains the alerts!

## 6. Cleanup

Long-running timers or open connections can cause unintended issues, such as:

*   Performance slowdowns (if `.z.ts` keeps running in the background)
*   Connection leaks (if clients don’t properly close hopen connections)

It is good practice therefore to stop the timer on the client and close the connection when you are finished with this tutorial:

```q
// Client
\t 0
```
```q
// Client
hclose h
```
    

*   `\t 0` disables `.z.ts`, stopping the automatic data generation
*   `hclose` closes the connection so the client can no longer communicate with the server process.

Next Steps
----------

At this stage, we have successfully set up:

*   A main server process (port 1234) handling trade data and real-time alerts
*   A client process simulating real-time trade data

The tutorial we have built here is designed to demonstrate just how powerful and elegant KDB-X is, even in its simplest form. In real life a professional KDB-X trading system would most likely make use of tick architecture, which:

*   Logs all incoming data to disk for durability.
*   Sends updates to multiple subscribers (real-time databases, analytics engines)
*   Manages high-frequency streams efficiently

To learn more about real-world KDB-X architecture, check out these resources:

*   Free KX Course: <a href="https://learninghub.kx.com/courses/kdb-architecture/" target="_blank">KDB-X Architecture</a>  A structured introduction to how KDB-X handles real-time and historical data.
*   GitHub: <a href="https://github.com/KxSystems/kdb-tick" target="_blank">kdb-tick</a>  The official repository for tick.q, a production-grade framework for real-time data ingestion, storage, and analytics.

This is how real-world trading systems ingest, process, and analyze billions of data points every day and now you have the foundation to build your own!
